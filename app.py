import streamlit as st
import datetime
import json
from pathlib import Path
import whisper
import tempfile
import os
import requests
from PIL import Image
from io import BytesIO
import google.generativeai as genai

# Configuration de la page
st.set_page_config(page_title="SynthÃ©tiseur de RÃªves", layout="centered")
st.title("ğŸŒ™ SynthÃ©tiseur de RÃªves")
st.markdown("Bienvenue ! Racontez-nous votre rÃªve...")

# Chargement des rÃªves enregistrÃ©s
def load_dreams():
    file = Path("dreams.json")
    if file.exists():
        try:
            with open(file, "r") as f:
                content = f.read().strip()
                if not content:
                    return []
                return json.loads(content)
        except json.JSONDecodeError:
            return []
    return []

# Sauvegarde d'un rÃªve
def save_dream(dream):
    dreams = load_dreams()
    dreams.append(dream)
    with open("dreams.json", "w") as f:
        json.dump(dreams, f, indent=2)

# Upload dâ€™un fichier audio
uploaded_file = st.file_uploader("ğŸ“¤ Uploader un fichier audio (.wav uniquement)", type=["wav"])

if uploaded_file is not None:
    st.audio(uploaded_file)
    st.success("Audio uploadÃ© avec succÃ¨s !")

    # Sauvegarde temporaire du fichier
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
        tmp_file.write(uploaded_file.read())
        tmp_file_path = tmp_file.name

    # Transcription locale avec Whisper (sans ffmpeg car .wav = direct)
    st.info("â³ Transcription en cours avec Whisper...")
    try:
        model = whisper.load_model("base")
        result = model.transcribe(tmp_file_path)
        transcribed_text = result["text"]
        st.text_area("ğŸ“ Texte du rÃªve :", transcribed_text, height=150)
    except Exception as e:
        st.error(f"âŒ Ã‰chec de la transcription audio : {e}")
        st.stop()

    # Analyse Ã©motionnelle avec Gemini
    st.info("ğŸ” Analyse Ã©motionnelle avec Gemini...")
    genai.configure(api_key=st.secrets["gemini_api_key"])

    emotion_prompt = f"""
    Tu es un dÃ©tecteur dâ€™Ã©motion. Lis ce rÃªve et rÃ©ponds uniquement par une Ã©motion dominante : heureux, triste, stressant, angoissÃ©, Ã©merveillÃ©, neutre, etc.

    RÃªve :
    \"\"\"{transcribed_text}\"\"\"

    RÃ©ponds uniquement par l'Ã©motion. Pas d'explication.
    """
    model_gemini = genai.GenerativeModel("gemini-1.5-flash")
    response = model_gemini.generate_content(emotion_prompt)
    emotion = response.text.strip()
    st.success(f"ğŸ­ Ã‰motion dÃ©tectÃ©e : {emotion}")

    # GÃ©nÃ©ration dâ€™image via ClipDrop
    st.info("ğŸ¨ GÃ©nÃ©ration de lâ€™image avec ClipDropâ€¦")
    headers = {
        "x-api-key": st.secrets["clipdrop_api_key"],
        "Content-Type": "application/json"
    }
    data = {
        "prompt": transcribed_text
    }

    response = requests.post(
        "https://clipdrop-api.co/text-to-image/v1",
        headers=headers,
        json=data,
    )

    if response.status_code == 200:
        image = Image.open(BytesIO(response.content))
        st.image(image, caption="ğŸŒ  Image gÃ©nÃ©rÃ©e Ã  partir du rÃªve")

        # Sauvegarde du rÃªve
        dream_data = {
            "date": datetime.datetime.now().strftime("%Y-%m-%d %H:%M"),
            "text": transcribed_text,
            "emotion": emotion,
            "image_url": ""
        }
        save_dream(dream_data)
    else:
        st.error("âŒ Ã‰chec de la gÃ©nÃ©ration d'image : " + response.text)

# Historique des rÃªves
if st.checkbox("ğŸ“œ Voir mes anciens rÃªves"):
    dreams = load_dreams()
    for dream in dreams:
        st.write(f"ğŸ—“ï¸ {dream['date']}")
        st.write(f"ğŸ’¬ {dream['text']}")
        st.write(f"ğŸ­ Ã‰motion : {dream['emotion']}")
        if dream.get("image_url"):
            st.image(dream["image_url"])
        st.markdown("---")
